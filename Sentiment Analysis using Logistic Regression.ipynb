{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of positive samples: 12500\n",
      "No of negative samples: 12500\n"
     ]
    }
   ],
   "source": [
    "pos_dst = './Data/test/pos/'\n",
    "neg_dst = './Data/test/neg/'\n",
    "\n",
    "# No of positive samples\n",
    "no_ps = len(os.listdir(pos_dst))\n",
    "\n",
    "# No of negative samples\n",
    "no_ns = len(os.listdir(neg_dst))\n",
    "\n",
    "print(\"No of positive samples:\", no_ps)\n",
    "print(\"No of negative samples:\", no_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {\"pos\":[],\"neg\":[]}\n",
    "\n",
    "list_pos = os.listdir(pos_dst)\n",
    "list_neg = os.listdir(neg_dst)\n",
    "i=0\n",
    "for pos,neg in zip(list_pos,list_neg):\n",
    "    \n",
    "    pos_f = open(os.path.join(pos_dst,pos),\"r\")\n",
    "    neg_f = open(os.path.join(neg_dst,neg),\"r\")\n",
    "    \n",
    "    # Read the text\n",
    "    pos_txt = pos_f.read()\n",
    "    neg_txt = neg_f.read()\n",
    "    \n",
    "    pos_f.close()\n",
    "    neg_f.close()\n",
    "    \n",
    "    train_dict[\"pos\"].append(pos_txt)\n",
    "    train_dict[\"neg\"].append(neg_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Process Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(txt):\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    \n",
    "    # Removing hyperlinks\n",
    "    txt = re.sub(r'http\\S+', '', txt)\n",
    "    \n",
    "    # Removing Line breaks\n",
    "    txt = re.sub(r'<br />', ' ', txt)\n",
    "    \n",
    "    # Only removing the hash # sign from the word\n",
    "    txt = re.sub(r'#','', txt)\n",
    "    \n",
    "    # Removing text.text types\n",
    "    match = re.search(r'[a-zA-Z]*\\.[a-zA-Z]*', txt)\n",
    "    while(match != None):\n",
    "        replace = \" \".join((txt[match.start():match.end()].split(\".\")))\n",
    "        txt = re.sub(r'[a-zA-Z]*\\.[a-zA-Z]*',replace, txt, 1)\n",
    "        match = re.search(r'[a-zA-Z]*\\.[a-zA-Z]*', txt)\n",
    "    \n",
    "    # Removing special characters and numbers\n",
    "    pattern = r'[^a-zA-z\\s]'\n",
    "    txt = re.sub(pattern, ' ', txt)\n",
    "    \n",
    "    txt_tokens = nltk.word_tokenize(txt)  \n",
    "    \n",
    "    clean_txt = []\n",
    "    \n",
    "    for word in txt_tokens:\n",
    "        word = word.lower()\n",
    "        word = word.strip(\" \")\n",
    "        if (word not in stopwords_english and  # remove stopwords\n",
    "                word not in string.punctuation):  # remove punctuation\n",
    "            \n",
    "            stem_word = stemmer.stem(word.strip('_'))# stemming word\n",
    "            clean_txt.append(stem_word)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return clean_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample:\n",
      "\n",
      "I loved this movie. It's a lot of laughs. The acting is good and the writing is really sharp. I'd rather see a hundred movies like this than THREE LORD OF THE RINGS repeating and repeating themselves.<br /><br />It's a low budget affair and seems to be shot on DV but looks good and Jay Mohr and Julianne Nicholson are great together. Why do you have a ten line minimum? I'm not a critic, just a patron.<br /><br />I doubt very much that Quentin Tarantino could write a picture this funny without filling it with masturbatory gratuitous violence. This movie should be seen on more screens than just one. I laughed from beginning to end. > \n",
      "\n",
      "Text After processing: \n",
      "\n",
      "['love', 'movi', 'lot', 'laugh', 'act', 'good', 'write', 'realli', 'sharp', 'rather', 'see', 'hundr', 'movi', 'like', 'three', 'lord', 'ring', 'repeat', 'repeat', 'low', 'budget', 'affair', 'seem', 'shot', 'dv', 'look', 'good', 'jay', 'mohr', 'juliann', 'nicholson', 'great', 'togeth', 'ten', 'line', 'minimum', 'critic', 'patron', 'doubt', 'much', 'quentin', 'tarantino', 'could', 'write', 'pictur', 'funni', 'without', 'fill', 'masturbatori', 'gratuit', 'violenc', 'movi', 'seen', 'screen', 'one', 'laugh', 'begin', 'end'] \n",
      "\n",
      "Negative sample:\n",
      "\n",
      "Another direct to video movie from Disney, that is essentially perfect for the kids. The problem with Kronk's New Groove I find is that everything that made the first movie a fun great ride is replaced with a more sad and sombre film. In this movie, Kronk learns a great deal of lessons at many others' expenses. It takes away much time that could be spent at creating a more enjoyable film.<br /><br />Kronk's New Groove deals with two stories: Yzma returns for payback and one Ms. Birdwell hopes to defeat Kronk's camp counseling championship. This all leads up to Kronk confronting his father and his disapproval over his son's direction in life.<br /><br />From Lord of the Rings to Michael Jackson's Thriller, Kronk's New Groove recycles every bit of time that it allows to entertain its viewers. If you loved the original, or are looking forward to the upcoming TV series about Kuzco, I recommend Kronk to his loyal fans. \n",
      "\n",
      "Text After processing: \n",
      "\n",
      "['anoth', 'direct', 'video', 'movi', 'disney', 'essenti', 'perfect', 'kid', 'problem', 'kronk', 'new', 'groov', 'find', 'everyth', 'made', 'first', 'movi', 'fun', 'great', 'ride', 'replac', 'sad', 'sombr', 'film', 'movi', 'kronk', 'learn', 'great', 'deal', 'lesson', 'mani', 'other', 'expens', 'take', 'away', 'much', 'time', 'could', 'spent', 'creat', 'enjoy', 'film', 'kronk', 'new', 'groov', 'deal', 'two', 'stori', 'yzma', 'return', 'payback', 'one', 'ms', 'birdwel', 'hope', 'defeat', 'kronk', 'camp', 'counsel', 'championship', 'lead', 'kronk', 'confront', 'father', 'disapprov', 'son', 'direct', 'life', 'lord', 'ring', 'michael', 'jackson', 'thriller', 'kronk', 'new', 'groov', 'recycl', 'everi', 'bit', 'time', 'allow', 'entertain', 'viewer', 'love', 'origin', 'look', 'forward', 'upcom', 'tv', 'seri', 'kuzco', 'recommend', 'kronk', 'loyal', 'fan'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample Positive Review\n",
    "print(\"Positive sample:\\n\")\n",
    "print(train_dict[\"pos\"][0],\"\\n\")\n",
    "\n",
    "# Processed positive sample \n",
    "print(\"Text After processing: \\n\")\n",
    "print(process(train_dict[\"pos\"][0]),\"\\n\")\n",
    "\n",
    "# Sample Negative Review\n",
    "print(\"Negative sample:\\n\")\n",
    "print(train_dict[\"neg\"][0],\"\\n\")\n",
    "\n",
    "# Processed Negative sample \n",
    "print(\"Text After processing: \\n\")\n",
    "print(process(train_dict[\"neg\"][0]),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Function to Build Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_freqs(tweets, ys):\n",
    "    \n",
    "    # Convert np array to list since zip needs an iterable.\n",
    "    # The squeeze is necessary or the list ends up with one element.\n",
    "    # Also note that this is just a NOP if ys is already a list.\n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "\n",
    "    # Start with an empty dictionary and populate it by looping over all tweets\n",
    "    # and over all processed words in each tweet.\n",
    "    freqs = {}\n",
    "    for y, tweet in zip(yslist, tweets):\n",
    "        for word in process(tweet):\n",
    "            pair = (word, y)\n",
    "            if pair in freqs:\n",
    "                freqs[pair] += 1\n",
    "            else:\n",
    "                freqs[pair] = 1\n",
    "\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Training Samples: 25000\n",
      "train_y.shape = (25000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Training Set \n",
    "train_x = train_dict[\"pos\"]+train_dict[\"neg\"]\n",
    "\n",
    "# Training Labels\n",
    "train_y = np.append(np.ones((len(train_dict[\"pos\"]),1)),\n",
    "                    np.zeros((len(train_dict[\"neg\"]), 1)),\n",
    "                    axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# Print the no of samples\n",
    "print(\"No of Training Samples:\",len(train_x))\n",
    "\n",
    "# Print the shape of train_y\n",
    "print(\"train_y.shape = \" + str(train_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Frequency Dictionary\n",
    "freqs = build_freqs(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "# Saving the Frequency Dictionary\n",
    "file = open('FreqDict', 'wb') \n",
    "pickle.dump(freqs, file) \n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Saved Frequency Dictionary\n",
    "\n",
    "file_to_read = open(\"FreqDict\", \"rb\")\n",
    "\n",
    "sfreqs = pickle.load(file_to_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: \"Bad\"\n",
      "No times used in the Positive sense: 1840\n",
      "No times used in the Negative sense: 7353 \n",
      "\n",
      "Word: \"Amazing\"\n",
      "No times used in the Positive sense: 1077\n",
      "No times used in the Negative sense: 366 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Word: \\\"Bad\\\"\")\n",
    "print(\"No times used in the Positive sense:\",sfreqs[('bad',1.0)])\n",
    "print(\"No times used in the Negative sense:\",sfreqs[('bad',0.0)],\"\\n\")\n",
    "\n",
    "print(\"Word: \\\"Amazing\\\"\")\n",
    "print(\"No times used in the Positive sense:\",sfreqs[(process(\"Amazing\")[0],1.0)])\n",
    "print(\"No times used in the Negative sense:\",sfreqs[(process(\"Amazing\")[0],0.0)],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tweet, freqs):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a list of words for one tweet\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "    Output: \n",
    "        x: a feature vector of dimension (1,3)\n",
    "    '''\n",
    "    # process_tweet tokenizes, stems, and removes stopwords\n",
    "    word_l = process(tweet)\n",
    "    # 3 elements in the form of a 1 x 3 vector\n",
    "    x = np.zeros((1, 3)) \n",
    "    \n",
    "    #bias term is set to 1\n",
    "    x[0,0] = 1 \n",
    "    \n",
    "    \n",
    "    # loop through each word in the list of words\n",
    "    for word in word_l:\n",
    "        \n",
    "        # increment the word count for the positive label 1\n",
    "        x[0,1] += freqs.get((word, 1.0),0)\n",
    "        \n",
    "        # increment the word count for the negative label 0\n",
    "        x[0,2] += freqs.get((word, 0.0),0)\n",
    "        \n",
    "    assert(x.shape == (1, 3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting each sample to 1x3 feature matrix\n",
    "\n",
    "X = np.zeros((len(train_x), 3))\n",
    "for i in range(len(train_x)):\n",
    "    X[i, :]= extract_features(train_x[i], sfreqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Features\n",
    "# np.save('TFeatures.npy', X) \n",
    "# # Saving the Labels\n",
    "# np.save('Tlabels.npy', train_y) \n",
    "\n",
    "# Loading the Saved Features\n",
    "Features = np.load('TFeatures.npy') \n",
    "labels = np.load('Tlabels.npy').ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(Features, labels, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score: 0.7032\n",
      "Testing F1 Score: 0.69792\n"
     ]
    }
   ],
   "source": [
    "print(\"Training F1 Score:\", f1_score(y_train, LR.predict(x_train), average='micro'))\n",
    "print(\"Testing F1 Score:\", f1_score(y_test, LR.predict(x_test),average='micro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
